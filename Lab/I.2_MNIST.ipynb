{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "387810fc-4e84-4f7e-8cb2-450a79f91e08",
   "metadata": {},
   "source": [
    "# MNIST dataset - Classifiying hand-written digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda02c12-6b7c-4cbf-b3b6-430e4fdd389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp \n",
    "import flax.linen as nn \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optax\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bebc967-ea8a-4d20-82cb-c31b2b1ae02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "digits = load_digits()\n",
    "Images = digits.data\n",
    "target = digits.target\n",
    "print(target.shape)\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9a53b7c-3f2d-4543-b79d-873d3ad58b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer Perceptron\n",
    "    \"\"\"\n",
    "    nhidden_units: int\n",
    "    nlayers = 1\n",
    "    nclasses = 10 # number of categories \n",
    "    \n",
    "    def setup(self):\n",
    "        self.layers = [nn.Dense(self.nhidden_units) for n in range(self.nlayers)]\n",
    "        self.final_layer = nn.Dense(self.nclasses)\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        for k, lyr in enumerate(self.layers):\n",
    "            x = lyr(x)\n",
    "            x = nn.relu(x)\n",
    "        x = self.final_layer(x)\n",
    "        x = nn.activation.softmax(x)\n",
    "        return x\n",
    "    \n",
    "# initializing the optimizer\n",
    "learning_rate = 1e-3\n",
    "optx = optax.adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e902b185-9ca8-491f-b8bf-ddee2df6b090",
   "metadata": {},
   "source": [
    "The target values we loaded are integers. We now write a code to one-hot encode them. For example, the category \"1\" would become [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5540928-b997-4439-b46e-20a38a8b4b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "target value: 8, corresponding one-hot vector: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(target[0])\n",
    "def one_hot_encoder(x):\n",
    "    nclasses = 10\n",
    "    out = np.zeros((x.shape[0], nclasses))\n",
    "    for i, x_ in enumerate(x):\n",
    "        out[i,x_] = 1.\n",
    "    return out\n",
    "target_oh = one_hot_encoder(target)\n",
    "# test\n",
    "print(f\"target value: {target[40]}, corresponding one-hot vector: {target_oh[40,:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a468aa-d570-4492-ab8f-fc8deed40bc9",
   "metadata": {},
   "source": [
    "## Fitting using a affine mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ab7ee2f-1bea-4479-9641-7c2d0b674fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1203, 64) (1203, 10)\n",
      "lossperex: (1203,)\n",
      "epoch: 0, loss function: 6.700168132781982\n",
      "epoch: 100, loss function: 0.19415205717086792\n",
      "epoch: 200, loss function: 0.06052875146269798\n",
      "epoch: 300, loss function: 0.0282761063426733\n",
      "epoch: 400, loss function: 0.01623375341296196\n",
      "epoch: 500, loss function: 0.010530908592045307\n",
      "epoch: 600, loss function: 0.007389646954834461\n",
      "epoch: 700, loss function: 0.005472120828926563\n",
      "epoch: 800, loss function: 0.004207364283502102\n",
      "epoch: 900, loss function: 0.0033350656740367413\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(Images, target_oh, test_size=0.33, random_state=42)\n",
    "print(x_train.shape, y_train.shape)\n",
    "# initialize the neural network \n",
    "model = MLP(50)\n",
    "params = model.init(jax.random.PRNGKey(0), x_test)\n",
    "opt_state = optx.init(params)\n",
    "\n",
    "# define the loss function \n",
    "@jax.jit\n",
    "def cat_cross_entropy(params, x, y_true):\n",
    "    \"\"\"\n",
    "    Categorical cross entropy \n",
    "    \"\"\"\n",
    "    y_pred = model.apply(params, x)\n",
    "    loss_per_example = jnp.sum(-y_true*jnp.log(y_pred), axis=1)\n",
    "    return jnp.mean(loss_per_example)\n",
    "\n",
    "loss_fn = cat_cross_entropy\n",
    "loss_grad_fn = jax.value_and_grad(cat_cross_entropy) # a function to evaluate the function and its gradient)\n",
    "\n",
    "# training loop\n",
    "n_epochs = 1000 #number of training epochs \n",
    "for e in range(n_epochs):\n",
    "    loss_val, grad = loss_grad_fn(params, x_train, y_train)\n",
    "    updates, opt_state = optx.update(grad, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    if e % 100 == 0:\n",
    "        print(f\"epoch: {e}, loss function: {loss_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e61faf-3a3d-4abb-9edc-954241271303",
   "metadata": {},
   "source": [
    "Test the learned function on some random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cbca75e5-2ec6-4584-b5ba-195279d6fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ture value: 9 predicted: 9\n"
     ]
    }
   ],
   "source": [
    "sample = np.random.randint(low=0, high=x_test.shape[0], size=(1,))\n",
    "y_pred = np.argmax(model.apply(params, x_test[sample,:]))\n",
    "print(f\"ture value: {np.argmax(y_test[sample,:])} predicted: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352a57e-0e56-47b1-b514-2249afd66b2f",
   "metadata": {},
   "source": [
    "Evaluate the training and test errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "497b3640-7462-47fd-b1cd-c5e5e5dde919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossperex: (594,)\n",
      "training loss: 0.0027055542450398207, test loss: 0.11141058057546616\n"
     ]
    }
   ],
   "source": [
    "tr_loss = cat_cross_entropy(params, x_train, y_train)\n",
    "te_loss = cat_cross_entropy(params, x_test, y_test)\n",
    "print(f\"training loss: {tr_loss}, test loss: {te_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256a74b-3c1e-45fd-81e7-d4f890756116",
   "metadata": {},
   "source": [
    "We now evaluate the training and test error. Does the model suffer from overfitting? from underfitting? from both?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f62803-06bd-4edd-b6df-26ab740bd583",
   "metadata": {},
   "source": [
    "One might argue that the curse of dimensionality is resulting from the fact that the basis we are using in multiple dimensions is a direct-product basis. To test the influence of this we not try to evaluate the accuracy of the model using a dimension-free prunning of the direct-product basis set. This prunnign is based on randomly sampling a subset of the full-direct product basis. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
